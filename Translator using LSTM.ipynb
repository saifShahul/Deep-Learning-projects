{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M0aPGVPKLiVK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-n2xpCKLo1A",
        "outputId": "2238e6cc-75d9-40fd-f146-ba3885ae4537"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,LSTM,Dense\n",
        "\n",
        "batch_size=64\n",
        "epochs=50\n",
        "latent_dim=256\n",
        "num_samples=10000\n",
        "\n",
        "data_path='/content/drive/MyDrive/archive (1)/fra.txt'"
      ],
      "metadata": {
        "id": "wWWyCYzcL0Yg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "metadata": {
        "id": "yi-MPe1BMBCW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters=sorted(list(input_characters))\n",
        "target_characters=sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens=len(input_characters)\n",
        "num_decoder_tokens=len(target_characters)\n",
        "\n",
        "max_encoder_seq_length=max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length=max([len(txt) for txt in target_texts])"
      ],
      "metadata": {
        "id": "51g4VArZMFni"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index=dict(\n",
        "    [(char,i) for i, char in enumerate(input_characters)])\n",
        "target_token_index=dict(\n",
        "[(char,i) for i, char in enumerate(target_characters)])"
      ],
      "metadata": {
        "id": "iQ7EPAYWMIBr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "metadata": {
        "id": "JmwRpivaMN1U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "metadata": {
        "id": "PsL4Yu8LMQmC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "EEi9_mc4MVtq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5w6Go0gMdxF",
        "outputId": "a734e4a5-c774-436c-d20f-7f90fa8649ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 5s 19ms/step - loss: 0.3067 - accuracy: 0.9080 - val_loss: 0.4590 - val_accuracy: 0.8678\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3014 - accuracy: 0.9097 - val_loss: 0.4592 - val_accuracy: 0.8687\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2974 - accuracy: 0.9112 - val_loss: 0.4613 - val_accuracy: 0.8678\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2934 - accuracy: 0.9121 - val_loss: 0.4627 - val_accuracy: 0.8684\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2899 - accuracy: 0.9132 - val_loss: 0.4649 - val_accuracy: 0.8679\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2867 - accuracy: 0.9141 - val_loss: 0.4568 - val_accuracy: 0.8689\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2825 - accuracy: 0.9155 - val_loss: 0.4613 - val_accuracy: 0.8686\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2791 - accuracy: 0.9161 - val_loss: 0.4636 - val_accuracy: 0.8691\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2760 - accuracy: 0.9172 - val_loss: 0.4627 - val_accuracy: 0.8681\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2722 - accuracy: 0.9183 - val_loss: 0.4622 - val_accuracy: 0.8703\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2693 - accuracy: 0.9190 - val_loss: 0.4611 - val_accuracy: 0.8709\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2654 - accuracy: 0.9204 - val_loss: 0.4579 - val_accuracy: 0.8708\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2624 - accuracy: 0.9210 - val_loss: 0.4646 - val_accuracy: 0.8701\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2597 - accuracy: 0.9218 - val_loss: 0.4620 - val_accuracy: 0.8710\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2561 - accuracy: 0.9233 - val_loss: 0.4653 - val_accuracy: 0.8700\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2528 - accuracy: 0.9237 - val_loss: 0.4678 - val_accuracy: 0.8698\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2501 - accuracy: 0.9248 - val_loss: 0.4716 - val_accuracy: 0.8690\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2468 - accuracy: 0.9252 - val_loss: 0.4661 - val_accuracy: 0.8706\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2442 - accuracy: 0.9266 - val_loss: 0.4690 - val_accuracy: 0.8699\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2414 - accuracy: 0.9269 - val_loss: 0.4708 - val_accuracy: 0.8698\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2381 - accuracy: 0.9280 - val_loss: 0.4751 - val_accuracy: 0.8699\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2357 - accuracy: 0.9286 - val_loss: 0.4744 - val_accuracy: 0.8696\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2329 - accuracy: 0.9297 - val_loss: 0.4756 - val_accuracy: 0.8695\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2296 - accuracy: 0.9304 - val_loss: 0.4767 - val_accuracy: 0.8705\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2272 - accuracy: 0.9314 - val_loss: 0.4780 - val_accuracy: 0.8695\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2246 - accuracy: 0.9320 - val_loss: 0.4746 - val_accuracy: 0.8706\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2216 - accuracy: 0.9329 - val_loss: 0.4822 - val_accuracy: 0.8699\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2196 - accuracy: 0.9334 - val_loss: 0.4790 - val_accuracy: 0.8709\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2166 - accuracy: 0.9344 - val_loss: 0.4843 - val_accuracy: 0.8697\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2144 - accuracy: 0.9350 - val_loss: 0.4846 - val_accuracy: 0.8707\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.2112 - accuracy: 0.9359 - val_loss: 0.4901 - val_accuracy: 0.8702\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.2088 - accuracy: 0.9366 - val_loss: 0.4912 - val_accuracy: 0.8701\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2068 - accuracy: 0.9369 - val_loss: 0.4878 - val_accuracy: 0.8706\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2045 - accuracy: 0.9380 - val_loss: 0.4855 - val_accuracy: 0.8704\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2016 - accuracy: 0.9387 - val_loss: 0.4915 - val_accuracy: 0.8707\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1999 - accuracy: 0.9393 - val_loss: 0.4924 - val_accuracy: 0.8717\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1972 - accuracy: 0.9402 - val_loss: 0.4945 - val_accuracy: 0.8705\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1954 - accuracy: 0.9406 - val_loss: 0.4960 - val_accuracy: 0.8705\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1931 - accuracy: 0.9413 - val_loss: 0.5011 - val_accuracy: 0.8697\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1909 - accuracy: 0.9418 - val_loss: 0.5033 - val_accuracy: 0.8704\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1886 - accuracy: 0.9423 - val_loss: 0.5051 - val_accuracy: 0.8697\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1871 - accuracy: 0.9427 - val_loss: 0.5090 - val_accuracy: 0.8702\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1844 - accuracy: 0.9438 - val_loss: 0.5117 - val_accuracy: 0.8698\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1833 - accuracy: 0.9440 - val_loss: 0.5139 - val_accuracy: 0.8704\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1806 - accuracy: 0.9451 - val_loss: 0.5129 - val_accuracy: 0.8709\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1786 - accuracy: 0.9454 - val_loss: 0.5205 - val_accuracy: 0.8692\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.1772 - accuracy: 0.9457 - val_loss: 0.5205 - val_accuracy: 0.8695\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1750 - accuracy: 0.9466 - val_loss: 0.5196 - val_accuracy: 0.8696\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1732 - accuracy: 0.9469 - val_loss: 0.5223 - val_accuracy: 0.8705\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1704 - accuracy: 0.9477 - val_loss: 0.5276 - val_accuracy: 0.8706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b2c7c384280>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('eng_french.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d73lflQxNH0K",
        "outputId": "ad79b85d-63f4-4dad-f33d-f3607c552bb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "metadata": {
        "id": "ydsl-IEHNMFw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "mSgjKOwjNP6g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(15):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzLw7r5DNd8g",
        "outputId": "e668fc49-a1b6-45f5-d60d-0c652d9d80a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Va !\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Restezaille !\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Restezaille !\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Qui est-ilâ€¯?\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Sous comment ?\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Poursuivez !\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Surinez-vois !\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Surinez partir !\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Attendez-le.\n",
            "\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Attendez-le.\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Attendez-le.\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attendez !\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attendez !\n",
            "\n"
          ]
        }
      ]
    }
  ]
}